<?xml version="1.0" encoding="UTF-8"?><testsuites failures="504" name="dependency-check" tests="286"><testsuite failures="0" id="0" name="/root/.m2/repository/com/zaxxer/HikariCP/2.5.1/HikariCP-2.5.1.jar" package="HikariCP-2.5.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="HikariCP-2.5.1.jar"/></testsuite><testsuite failures="0" id="1" name="/root/.m2/repository/pl/edu/icm/JLargeArrays/1.5/JLargeArrays-1.5.jar" package="JLargeArrays-1.5.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="JLargeArrays-1.5.jar"/></testsuite><testsuite failures="0" id="2" name="/root/.m2/repository/com/github/wendykierp/JTransforms/3.1/JTransforms-3.1.jar" package="JTransforms-3.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="JTransforms-3.1.jar"/></testsuite><testsuite failures="0" id="3" name="/root/.m2/repository/org/roaringbitmap/RoaringBitmap/0.9.0/RoaringBitmap-0.9.0.jar" package="RoaringBitmap-0.9.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="RoaringBitmap-0.9.0.jar"/></testsuite><testsuite failures="0" id="4" name="/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar" package="ST4-4.0.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="ST4-4.0.4.jar"/></testsuite><testsuite failures="0" id="5" name="/root/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar" package="activation-1.1.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="activation-1.1.1.jar"/></testsuite><testsuite failures="0" id="6" name="/root/.m2/repository/io/airlift/aircompressor/0.19/aircompressor-0.19.jar" package="aircompressor-0.19.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="aircompressor-0.19.jar"/></testsuite><testsuite failures="0" id="7" name="/root/.m2/repository/org/typelevel/algebra_2.12/2.0.0-M2/algebra_2.12-2.0.0-M2.jar" package="algebra_2.12-2.0.0-M2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="algebra_2.12-2.0.0-M2.jar"/></testsuite><testsuite failures="0" id="8" name="/root/.m2/repository/org/jetbrains/annotations/17.0.0/annotations-17.0.0.jar" package="annotations-17.0.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="annotations-17.0.0.jar"/></testsuite><testsuite failures="0" id="9" name="/root/.m2/repository/org/antlr/antlr-runtime/3.5.2/antlr-runtime-3.5.2.jar" package="antlr-runtime-3.5.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="antlr-runtime-3.5.2.jar"/></testsuite><testsuite failures="0" id="10" name="/root/.m2/repository/org/antlr/antlr4-runtime/4.8/antlr4-runtime-4.8.jar" package="antlr4-runtime-4.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="antlr4-runtime-4.8.jar"/></testsuite><testsuite failures="0" id="11" name="/root/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.6.1/aopalliance-repackaged-2.6.1.jar" package="aopalliance-repackaged-2.6.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="aopalliance-repackaged-2.6.1.jar"/></testsuite><testsuite failures="0" id="12" name="/root/.m2/repository/dev/ludovic/netlib/arpack/2.2.0/arpack-2.2.0.jar" package="arpack-2.2.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="arpack-2.2.0.jar"/></testsuite><testsuite failures="0" id="13" name="/root/.m2/repository/net/sourceforge/f2j/arpack_combined_all/0.1/arpack_combined_all-0.1.jar" package="arpack_combined_all-0.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="arpack_combined_all-0.1.jar"/></testsuite><testsuite failures="0" id="14" name="/root/.m2/repository/org/apache/arrow/arrow-memory-core/2.0.0/arrow-memory-core-2.0.0.jar" package="arrow-memory-core-2.0.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="arrow-memory-core-2.0.0.jar"/></testsuite><testsuite failures="0" id="15" name="/root/.m2/repository/org/ow2/asm/asm/7.1/asm-7.1.jar" package="asm-7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="asm-7.1.jar"/></testsuite><testsuite failures="0" id="16" name="/root/.m2/repository/org/ow2/asm/asm-analysis/7.1/asm-analysis-7.1.jar" package="asm-analysis-7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="asm-analysis-7.1.jar"/></testsuite><testsuite failures="0" id="17" name="/root/.m2/repository/org/ow2/asm/asm-commons/7.1/asm-commons-7.1.jar" package="asm-commons-7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="asm-commons-7.1.jar"/></testsuite><testsuite failures="0" id="18" name="/root/.m2/repository/org/ow2/asm/asm-tree/7.1/asm-tree-7.1.jar" package="asm-tree-7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="asm-tree-7.1.jar"/></testsuite><testsuite failures="0" id="19" name="/root/.m2/repository/org/ow2/asm/asm-util/7.1/asm-util-7.1.jar" package="asm-util-7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="asm-util-7.1.jar"/></testsuite><testsuite failures="0" id="20" name="/root/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar" package="audience-annotations-0.5.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="audience-annotations-0.5.0.jar"/></testsuite><testsuite failures="1" id="21" name="/root/.m2/repository/org/apache/avro/avro/1.10.2/avro-1.10.2.jar" package="avro-1.10.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2019-17195" name="pkg:maven/org.apache.avro/avro@1.10.2"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>Connect2id Nimbus JOSE+JWT before v7.9 can throw various uncaught exceptions while parsing a JWT, which could result in an application crash (potential information disclosure) or a potential authentication bypass.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro/1.10.2/avro-1.10.2.jar</system-err></testcase></testsuite><testsuite failures="0" id="22" name="/root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/avro.js" package="avro-ipc-1.10.2.jar: avro.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="avro-ipc-1.10.2.jar: avro.js"/></testsuite><testsuite failures="0" id="23" name="/root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/g.bar.js" package="avro-ipc-1.10.2.jar: g.bar.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="avro-ipc-1.10.2.jar: g.bar.js"/></testsuite><testsuite failures="6" id="24" name="/root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js" package="avro-ipc-1.10.2.jar: jquery-1.4.2.min.js" skipped="0" tests="6" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2011-4969" name="pkg:javascript/jquery@1.4.2.min"><failure message="cvssV2: MEDIUM, score: 4.3 (/AV:N/AC:M/Au:N/C:N/I:P/A:N)"/><system-out>Cross-site scripting (XSS) vulnerability in jQuery before 1.6.3, when using location.hash to select elements, allows remote attackers to inject arbitrary web script or HTML via a crafted tag.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js</system-err></testcase><testcase classname="CVE-2012-6708" name="pkg:javascript/jquery@1.4.2.min"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>jQuery before 1.9.0 is vulnerable to Cross-site Scripting (XSS) attacks. The jQuery(strInput) function does not differentiate selectors from HTML in a reliable fashion. In vulnerable versions, jQuery determined whether the input was HTML by looking for the &apos;&lt;&apos; character anywhere in the string, giving attackers more flexibility when attempting to construct a malicious payload. In fixed versions, jQuery only deems the input to be HTML if it explicitly starts with the &apos;&lt;&apos; character, limiting exploitability only to attackers who can control the beginning of a string, which is far less common.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js</system-err></testcase><testcase classname="CVE-2015-9251" name="pkg:javascript/jquery@1.4.2.min"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>jQuery before 3.0.0 is vulnerable to Cross-site Scripting (XSS) attacks when a cross-domain Ajax request is performed without the dataType option, causing text/javascript responses to be executed.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js</system-err></testcase><testcase classname="CVE-2019-11358" name="pkg:javascript/jquery@1.4.2.min"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>jQuery before 3.4.0, as used in Drupal, Backdrop CMS, and other products, mishandles jQuery.extend(true, {}, ...) because of Object.prototype pollution. If an unsanitized source object contained an enumerable __proto__ property, it could extend the native Object.prototype.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js</system-err></testcase><testcase classname="CVE-2020-11022" name="pkg:javascript/jquery@1.4.2.min"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>In jQuery versions greater than or equal to 1.2 and before 3.5.0, passing HTML from untrusted sources - even after sanitizing it - to one of jQuery&apos;s DOM manipulation methods (i.e. .html(), .append(), and others) may execute untrusted code. This problem is patched in jQuery 3.5.0.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js</system-err></testcase><testcase classname="CVE-2020-11023" name="pkg:javascript/jquery@1.4.2.min"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>In jQuery versions greater than or equal to 1.0.3 and before 3.5.0, passing HTML containing &lt;option&gt; elements from untrusted sources - even after sanitizing it - to one of jQuery&apos;s DOM manipulation methods (i.e. .html(), .append(), and others) may execute untrusted code. This problem is patched in jQuery 3.5.0.</system-out><system-err>location: /root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery-1.4.2.min.js</system-err></testcase></testsuite><testsuite failures="0" id="25" name="/root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/jquery.tipsy.js" package="avro-ipc-1.10.2.jar: jquery.tipsy.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="avro-ipc-1.10.2.jar: jquery.tipsy.js"/></testsuite><testsuite failures="0" id="26" name="/root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/protovis-r3.2.js" package="avro-ipc-1.10.2.jar: protovis-r3.2.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="avro-ipc-1.10.2.jar: protovis-r3.2.js"/></testsuite><testsuite failures="0" id="27" name="/root/.m2/repository/org/apache/avro/avro-ipc/1.10.2/avro-ipc-1.10.2.jar/org/apache/avro/ipc/stats/static/tipsy.js" package="avro-ipc-1.10.2.jar: tipsy.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="avro-ipc-1.10.2.jar: tipsy.js"/></testsuite><testsuite failures="0" id="28" name="/root/.m2/repository/dev/ludovic/netlib/blas/2.2.0/blas-2.2.0.jar" package="blas-2.2.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="blas-2.2.0.jar"/></testsuite><testsuite failures="0" id="29" name="/root/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar" package="bonecp-0.8.0.RELEASE.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="bonecp-0.8.0.RELEASE.jar"/></testsuite><testsuite failures="0" id="30" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/bootstrap.bundle.min.js" package="bootstrap.bundle.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="bootstrap.bundle.min.js"/></testsuite><testsuite failures="0" id="31" name="/root/.m2/repository/org/scalanlp/breeze-macros_2.12/1.0/breeze-macros_2.12-1.0.jar" package="breeze-macros_2.12-1.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="breeze-macros_2.12-1.0.jar"/></testsuite><testsuite failures="0" id="32" name="/root/.m2/repository/org/scalanlp/breeze_2.12/1.0/breeze_2.12-1.0.jar" package="breeze_2.12-1.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="breeze_2.12-1.0.jar"/></testsuite><testsuite failures="0" id="33" name="/root/.m2/repository/org/typelevel/cats-kernel_2.12/2.0.0-M4/cats-kernel_2.12-2.0.0-M4.jar" package="cats-kernel_2.12-2.0.0-M4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="cats-kernel_2.12-2.0.0-M4.jar"/></testsuite><testsuite failures="0" id="34" name="/root/.m2/repository/com/twitter/chill-java/0.10.0/chill-java-0.10.0.jar" package="chill-java-0.10.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="chill-java-0.10.0.jar"/></testsuite><testsuite failures="0" id="35" name="/root/.m2/repository/com/twitter/chill_2.12/0.10.0/chill_2.12-0.10.0.jar" package="chill_2.12-0.10.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="chill_2.12-0.10.0.jar"/></testsuite><testsuite failures="0" id="36" name="/root/.m2/repository/org/clapper/classutil_2.12/1.5.1/classutil_2.12-1.5.1.jar" package="classutil_2.12-1.5.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="classutil_2.12-1.5.1.jar"/></testsuite><testsuite failures="0" id="37" name="/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar" package="commons-cli-1.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-cli-1.2.jar"/></testsuite><testsuite failures="0" id="38" name="/root/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar" package="commons-codec-1.15.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-codec-1.15.jar"/></testsuite><testsuite failures="0" id="39" name="/root/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar" package="commons-collections-3.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-collections-3.2.2.jar"/></testsuite><testsuite failures="0" id="40" name="/root/.m2/repository/org/codehaus/janino/commons-compiler/3.1.4/commons-compiler-3.1.4.jar" package="commons-compiler-3.1.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-compiler-3.1.4.jar"/></testsuite><testsuite failures="0" id="41" name="/root/.m2/repository/org/apache/commons/commons-compress/1.20/commons-compress-1.20.jar" package="commons-compress-1.20.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-compress-1.20.jar"/></testsuite><testsuite failures="0" id="42" name="/root/.m2/repository/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar" package="commons-crypto-1.1.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-crypto-1.1.0.jar"/></testsuite><testsuite failures="0" id="43" name="/root/.m2/repository/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar/org/apache/commons/crypto/native/Windows/x86_64/commons-crypto.dll" package="commons-crypto-1.1.0.jar: commons-crypto.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-crypto-1.1.0.jar: commons-crypto.dll"/></testsuite><testsuite failures="0" id="44" name="/root/.m2/repository/org/apache/commons/commons-crypto/1.1.0/commons-crypto-1.1.0.jar/org/apache/commons/crypto/native/Windows/x86/commons-crypto.dll" package="commons-crypto-1.1.0.jar: commons-crypto.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-crypto-1.1.0.jar: commons-crypto.dll"/></testsuite><testsuite failures="0" id="45" name="/root/.m2/repository/commons-dbcp/commons-dbcp/1.4/commons-dbcp-1.4.jar" package="commons-dbcp-1.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-dbcp-1.4.jar"/></testsuite><testsuite failures="0" id="46" name="/root/.m2/repository/commons-io/commons-io/2.8.0/commons-io-2.8.0.jar" package="commons-io-2.8.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-io-2.8.0.jar"/></testsuite><testsuite failures="0" id="47" name="/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar" package="commons-lang-2.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-lang-2.6.jar"/></testsuite><testsuite failures="0" id="48" name="/root/.m2/repository/org/apache/commons/commons-lang3/3.12.0/commons-lang3-3.12.0.jar" package="commons-lang3-3.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-lang3-3.12.0.jar"/></testsuite><testsuite failures="0" id="49" name="/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar" package="commons-logging-1.1.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-logging-1.1.3.jar"/></testsuite><testsuite failures="0" id="50" name="/root/.m2/repository/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar" package="commons-math3-3.4.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-math3-3.4.1.jar"/></testsuite><testsuite failures="0" id="51" name="/root/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar" package="commons-net-3.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-net-3.1.jar"/></testsuite><testsuite failures="0" id="52" name="/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar" package="commons-pool-1.5.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-pool-1.5.4.jar"/></testsuite><testsuite failures="0" id="53" name="/root/.m2/repository/commons-pool/commons-pool/1.6/commons-pool-1.6.jar" package="commons-pool-1.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-pool-1.6.jar"/></testsuite><testsuite failures="0" id="54" name="/root/.m2/repository/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar" package="commons-pool2-2.6.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-pool2-2.6.2.jar"/></testsuite><testsuite failures="0" id="55" name="/root/.m2/repository/org/apache/commons/commons-text/1.6/commons-text-1.6.jar" package="commons-text-1.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="commons-text-1.6.jar"/></testsuite><testsuite failures="0" id="56" name="/root/.m2/repository/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar" package="compress-lzf-1.0.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="compress-lzf-1.0.3.jar"/></testsuite><testsuite failures="0" id="57" name="/root/.m2/repository/com/github/fommil/netlib/core/1.1.2/core-1.1.2.jar" package="core-1.1.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="core-1.1.2.jar"/></testsuite><testsuite failures="0" id="58" name="/root/.m2/repository/org/apache/curator/curator-client/2.13.0/curator-client-2.13.0.jar" package="curator-client-2.13.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="curator-client-2.13.0.jar"/></testsuite><testsuite failures="0" id="59" name="/root/.m2/repository/org/apache/curator/curator-framework/2.13.0/curator-framework-2.13.0.jar" package="curator-framework-2.13.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="curator-framework-2.13.0.jar"/></testsuite><testsuite failures="0" id="60" name="/root/.m2/repository/org/apache/curator/curator-recipes/2.13.0/curator-recipes-2.13.0.jar" package="curator-recipes-2.13.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="curator-recipes-2.13.0.jar"/></testsuite><testsuite failures="0" id="61" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/d3.min.js" package="d3.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="d3.min.js"/></testsuite><testsuite failures="0" id="62" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/dagre-d3.min.js" package="dagre-d3.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="dagre-d3.min.js"/></testsuite><testsuite failures="0" id="63" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/dataTables.bootstrap4.1.10.20.min.js" package="dataTables.bootstrap4.1.10.20.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="dataTables.bootstrap4.1.10.20.min.js"/></testsuite><testsuite failures="0" id="64" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/dataTables.rowsGroup.js" package="dataTables.rowsGroup.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="dataTables.rowsGroup.js"/></testsuite><testsuite failures="0" id="65" name="/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/4.2.4/datanucleus-api-jdo-4.2.4.jar" package="datanucleus-api-jdo-4.2.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="datanucleus-api-jdo-4.2.4.jar"/></testsuite><testsuite failures="0" id="66" name="/root/.m2/repository/org/datanucleus/datanucleus-core/4.1.17/datanucleus-core-4.1.17.jar" package="datanucleus-core-4.1.17.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="datanucleus-core-4.1.17.jar"/></testsuite><testsuite failures="0" id="67" name="/root/.m2/repository/org/datanucleus/datanucleus-rdbms/4.1.19/datanucleus-rdbms-4.1.19.jar" package="datanucleus-rdbms-4.1.19.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="datanucleus-rdbms-4.1.19.jar"/></testsuite><testsuite failures="0" id="68" name="/root/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar" package="derby-10.14.2.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="derby-10.14.2.0.jar"/></testsuite><testsuite failures="0" id="69" name="/root/.m2/repository/com/github/joshelser/dropwizard-metrics-hadoop-metrics2-reporter/0.1.2/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar" package="dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar"/></testsuite><testsuite failures="0" id="70" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/executorspage.js" package="executorspage.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="executorspage.js"/></testsuite><testsuite failures="0" id="71" name="/root/.m2/repository/com/google/flatbuffers/flatbuffers-java/1.9.0/flatbuffers-java-1.9.0.jar" package="flatbuffers-java-1.9.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="flatbuffers-java-1.9.0.jar"/></testsuite><testsuite failures="0" id="72" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/graphlib-dot.min.js" package="graphlib-dot.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="graphlib-dot.min.js"/></testsuite><testsuite failures="0" id="73" name="/root/.m2/repository/org/clapper/grizzled-scala_2.12/4.9.3/grizzled-scala_2.12-4.9.3.jar" package="grizzled-scala_2.12-4.9.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="grizzled-scala_2.12-4.9.3.jar"/></testsuite><testsuite failures="0" id="74" name="/root/.m2/repository/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar" package="gson-2.2.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="gson-2.2.4.jar"/></testsuite><testsuite failures="2" id="75" name="/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar" package="guava-14.0.1.jar" skipped="0" tests="2" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-10237" name="pkg:maven/com.google.guava/guava@14.0.1"><failure message="cvssV3: MEDIUM, score: 5.9 (CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>Unbounded memory allocation in Google Guava 11.0 through 24.x before 24.1.1 allows remote attackers to conduct denial of service attacks against servers that depend on this library and deserialize attacker-provided data, because the AtomicDoubleArray class (when serialized with Java serialization) and the CompoundOrdering class (when serialized with GWT serialization) perform eager allocation without appropriate checks on what a client has sent and whether the data size is reasonable.</system-out><system-err>location: /root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar</system-err></testcase><testcase classname="CVE-2020-8908" name="pkg:maven/com.google.guava/guava@14.0.1"><failure message="cvssV3: LOW, score: 3.3 (CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:L/I:N/A:N)"/><system-out>A temp directory creation vulnerability exists in all versions of Guava, allowing an attacker with access to the machine to potentially access data in a temporary directory created by the Guava API com.google.common.io.Files.createTempDir(). By default, on unix-like systems, the created directory is world-readable (readable by an attacker with access to the system). The method in question has been marked @Deprecated in versions 30.0 and later and should not be used. For Android developers, we recommend choosing a temporary directory API provided by Android, such as context.getCacheDir(). For other Java developers, we recommend migrating to the Java 7 API java.nio.file.Files.createTempDirectory() which explicitly configures permissions of 700, or configuring the Java runtime&apos;s java.io.tmpdir system property to point to a location whose permissions are appropriately configured.</system-out><system-err>location: /root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar</system-err></testcase></testsuite><testsuite failures="0" id="76" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar" package="hadoop-client-api-3.3.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar"/></testsuite><testsuite failures="0" id="77" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar/META-INF/maven/org.apache.hadoop/hadoop-mapreduce-client-core/pom.xml" package="hadoop-client-api-3.3.1.jar (shaded: org.apache.hadoop:hadoop-mapreduce-client-core:3.3.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar (shaded: org.apache.hadoop:hadoop-mapreduce-client-core:3.3.1)"/></testsuite><testsuite failures="0" id="78" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar/webapps/static/jquery/jquery-ui-1.12.1.custom.min.js" package="hadoop-client-api-3.3.1.jar: jquery-ui-1.12.1.custom.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar: jquery-ui-1.12.1.custom.min.js"/></testsuite><testsuite failures="0" id="79" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar/webapps/static/dt-1.10.18/js/jquery.dataTables.min.js" package="hadoop-client-api-3.3.1.jar: jquery.dataTables.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar: jquery.dataTables.min.js"/></testsuite><testsuite failures="0" id="80" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar/webapps/static/jt/jquery.jstree.js" package="hadoop-client-api-3.3.1.jar: jquery.jstree.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar: jquery.jstree.js"/></testsuite><testsuite failures="0" id="81" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar/webapps/static/dt-sorting/natural.js" package="hadoop-client-api-3.3.1.jar: natural.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar: natural.js"/></testsuite><testsuite failures="0" id="82" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.1/hadoop-client-api-3.3.1.jar/webapps/static/yarn.dt.plugins.js" package="hadoop-client-api-3.3.1.jar: yarn.dt.plugins.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-api-3.3.1.jar: yarn.dt.plugins.js"/></testsuite><testsuite failures="0" id="83" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-core/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.core:jackson-core:2.10.5)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.core:jackson-core:2.10.5)"/></testsuite><testsuite failures="0" id="84" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.core:jackson-databind:2.10.5.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.core:jackson-databind:2.10.5.1)"/></testsuite><testsuite failures="0" id="85" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.fasterxml.jackson.jaxrs/jackson-jaxrs-base/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:2.10.5)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.jaxrs:jackson-jaxrs-base:2.10.5)"/></testsuite><testsuite failures="0" id="86" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.fasterxml.jackson.jaxrs/jackson-jaxrs-json-provider/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:2.10.5)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.jaxrs:jackson-jaxrs-json-provider:2.10.5)"/></testsuite><testsuite failures="0" id="87" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.fasterxml.jackson.module/jackson-module-jaxb-annotations/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.module:jackson-module-jaxb-annotations:2.10.5)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.jackson.module:jackson-module-jaxb-annotations:2.10.5)"/></testsuite><testsuite failures="0" id="88" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.fasterxml.woodstox/woodstox-core/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.woodstox:woodstox-core:5.3.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.fasterxml.woodstox:woodstox-core:5.3.0)"/></testsuite><testsuite failures="0" id="89" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.github.stephenc.jcip/jcip-annotations/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.github.stephenc.jcip:jcip-annotations:1.0-1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.github.stephenc.jcip:jcip-annotations:1.0-1)"/></testsuite><testsuite failures="0" id="90" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.errorprone/error_prone_annotations/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.errorprone:error_prone_annotations:2.5.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.errorprone:error_prone_annotations:2.5.1)"/></testsuite><testsuite failures="0" id="91" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.guava/failureaccess/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.guava:failureaccess:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.guava:failureaccess:1.0.1)"/></testsuite><testsuite failures="0" id="92" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.guava/guava/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.guava:guava:30.1.1-jre)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.guava:guava:30.1.1-jre)"/></testsuite><testsuite failures="0" id="93" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.guava/listenablefuture/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.guava:listenablefuture:9999.0-empty-to-avoid-conflict-with-guava)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.guava:listenablefuture:9999.0-empty-to-avoid-conflict-with-guava)"/></testsuite><testsuite failures="0" id="94" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.j2objc/j2objc-annotations/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.j2objc:j2objc-annotations:1.3)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.j2objc:j2objc-annotations:1.3)"/></testsuite><testsuite failures="0" id="95" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.protobuf/protobuf-java/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.protobuf:protobuf-java:3.7.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.protobuf:protobuf-java:3.7.1)"/></testsuite><testsuite failures="0" id="96" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.google.re2j/re2j/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.google.re2j:re2j:1.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.google.re2j:re2j:1.1)"/></testsuite><testsuite failures="0" id="97" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.nimbusds/nimbus-jose-jwt/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.nimbusds:nimbus-jose-jwt:9.8.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.nimbusds:nimbus-jose-jwt:9.8.1)"/></testsuite><testsuite failures="0" id="98" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.squareup.okhttp/okhttp/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.squareup.okhttp:okhttp:2.7.5)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.squareup.okhttp:okhttp:2.7.5)"/></testsuite><testsuite failures="0" id="99" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.squareup.okio/okio/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.squareup.okio:okio:1.6.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.squareup.okio:okio:1.6.0)"/></testsuite><testsuite failures="0" id="100" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.sun.jersey/jersey-core/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.sun.jersey:jersey-core:1.19)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.sun.jersey:jersey-core:1.19)"/></testsuite><testsuite failures="0" id="101" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/com.thoughtworks.paranamer/paranamer/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: com.thoughtworks.paranamer:paranamer:2.3)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: com.thoughtworks.paranamer:paranamer:2.3)"/></testsuite><testsuite failures="0" id="102" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/commons-beanutils/commons-beanutils/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: commons-beanutils:commons-beanutils:1.9.4)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: commons-beanutils:commons-beanutils:1.9.4)"/></testsuite><testsuite failures="0" id="103" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/commons-codec/commons-codec/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: commons-codec:commons-codec:1.11)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: commons-codec:commons-codec:1.11)"/></testsuite><testsuite failures="0" id="104" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/commons-net/commons-net/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: commons-net:commons-net:3.6)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: commons-net:commons-net:3.6)"/></testsuite><testsuite failures="0" id="105" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/dnsjava/dnsjava/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: dnsjava:dnsjava:2.1.7)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: dnsjava:dnsjava:2.1.7)"/></testsuite><testsuite failures="0" id="106" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/jakarta.activation/jakarta.activation-api/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: jakarta.activation:jakarta.activation-api:1.2.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: jakarta.activation:jakarta.activation-api:1.2.1)"/></testsuite><testsuite failures="0" id="107" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/javax.ws.rs/jsr311-api/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: javax.ws.rs:jsr311-api:1.1.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: javax.ws.rs:jsr311-api:1.1.1)"/></testsuite><testsuite failures="0" id="108" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/net.minidev/accessors-smart/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: net.minidev:accessors-smart:2.4.2)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: net.minidev:accessors-smart:2.4.2)"/></testsuite><testsuite failures="0" id="109" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/net.minidev/json-smart/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: net.minidev:json-smart:1.3.2)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: net.minidev:json-smart:1.3.2)"/></testsuite><testsuite failures="0" id="110" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.avro/avro/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.avro:avro:1.7.7)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.avro:avro:1.7.7)"/></testsuite><testsuite failures="0" id="111" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.commons/commons-compress/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-compress:1.19)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-compress:1.19)"/></testsuite><testsuite failures="0" id="112" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.commons/commons-configuration2/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-configuration2:2.1.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-configuration2:2.1.1)"/></testsuite><testsuite failures="0" id="113" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.commons/commons-lang3/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-lang3:3.7)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-lang3:3.7)"/></testsuite><testsuite failures="0" id="114" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.commons/commons-math3/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-math3:3.1.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-math3:3.1.1)"/></testsuite><testsuite failures="0" id="115" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.commons/commons-text/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-text:1.4)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.commons:commons-text:1.4)"/></testsuite><testsuite failures="0" id="116" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.curator/curator-client/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.curator:curator-client:4.2.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.curator:curator-client:4.2.0)"/></testsuite><testsuite failures="0" id="117" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.curator/curator-framework/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.curator:curator-framework:4.2.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.curator:curator-framework:4.2.0)"/></testsuite><testsuite failures="0" id="118" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.curator/curator-recipes/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.curator:curator-recipes:4.2.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.curator:curator-recipes:4.2.0)"/></testsuite><testsuite failures="5" id="119" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.hadoop.thirdparty:hadoop-shaded-guava:1.1.1)" skipped="0" tests="5" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2013-2192" name="pkg:maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava@1.1.1"><failure message="cvssV2: LOW, score: 3.2 (/AV:A/AC:H/Au:N/C:P/I:P/A:N)"/><system-out>The RPC protocol implementation in Apache Hadoop 2.x before 2.0.6-alpha, 0.23.x before 0.23.9, and 1.x before 1.2.1, when the Kerberos security features are enabled, allows man-in-the-middle attackers to disable bidirectional authentication and obtain sensitive information by forcing a downgrade to simple authentication.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava/pom.xml</system-err></testcase><testcase classname="CVE-2015-7430" name="pkg:maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava@1.1.1"><failure message="cvssV3: HIGH, score: 8.4 (CVSS:3.0/AV:L/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>The Hadoop connector 1.1.1, 2.4, 2.5, and 2.7.0-0 before 2.7.0-3 for IBM Spectrum Scale and General Parallel File System (GPFS) allows local users to read or write to arbitrary GPFS data via unspecified vectors.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava/pom.xml</system-err></testcase><testcase classname="CVE-2016-5001" name="pkg:maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava@1.1.1"><failure message="cvssV3: MEDIUM, score: 5.5 (CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N)"/><system-out>This is an information disclosure vulnerability in Apache Hadoop before 2.6.4 and 2.7.x before 2.7.2 in the short-circuit reads feature of HDFS. A local user on an HDFS DataNode may be able to craft a block token that grants unauthorized read access to random files by guessing certain fields in the token.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava/pom.xml</system-err></testcase><testcase classname="CVE-2017-3161" name="pkg:maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava@1.1.1"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>The HDFS web UI in Apache Hadoop before 2.7.0 is vulnerable to a cross-site scripting (XSS) attack through an unescaped query parameter.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava/pom.xml</system-err></testcase><testcase classname="CVE-2017-3162" name="pkg:maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava@1.1.1"><failure message="cvssV3: HIGH, score: 7.3 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:L)"/><system-out>HDFS clients interact with a servlet on the DataNode to browse the HDFS namespace. The NameNode is provided as a query parameter that is not validated in Apache Hadoop before 2.7.0.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.hadoop.thirdparty/hadoop-shaded-guava/pom.xml</system-err></testcase></testsuite><testsuite failures="0" id="120" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.httpcomponents/httpcore/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.httpcomponents:httpcore:4.4.13)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.httpcomponents:httpcore:4.4.13)"/></testsuite><testsuite failures="0" id="121" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-admin/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-admin:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-admin:1.0.1)"/></testsuite><testsuite failures="0" id="122" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-client/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-client:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-client:1.0.1)"/></testsuite><testsuite failures="0" id="123" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-common/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-common:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-common:1.0.1)"/></testsuite><testsuite failures="0" id="124" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-core/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-core:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-core:1.0.1)"/></testsuite><testsuite failures="0" id="125" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-crypto/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-crypto:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-crypto:1.0.1)"/></testsuite><testsuite failures="0" id="126" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-identity/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-identity:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-identity:1.0.1)"/></testsuite><testsuite failures="0" id="127" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-server/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-server:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-server:1.0.1)"/></testsuite><testsuite failures="0" id="128" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-simplekdc/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-simplekdc:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-simplekdc:1.0.1)"/></testsuite><testsuite failures="0" id="129" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerb-util/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-util:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerb-util:1.0.1)"/></testsuite><testsuite failures="0" id="130" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerby-asn1/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-asn1:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-asn1:1.0.1)"/></testsuite><testsuite failures="0" id="131" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerby-config/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-config:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-config:1.0.1)"/></testsuite><testsuite failures="0" id="132" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerby-pkix/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-pkix:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-pkix:1.0.1)"/></testsuite><testsuite failures="0" id="133" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerby-util/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-util:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-util:1.0.1)"/></testsuite><testsuite failures="0" id="134" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/kerby-xdr/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-xdr:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:kerby-xdr:1.0.1)"/></testsuite><testsuite failures="0" id="135" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.apache.kerby/token-provider/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:token-provider:1.0.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.apache.kerby:token-provider:1.0.1)"/></testsuite><testsuite failures="0" id="136" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.codehaus.mojo/animal-sniffer-annotations/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.codehaus.mojo:animal-sniffer-annotations:1.17)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.codehaus.mojo:animal-sniffer-annotations:1.17)"/></testsuite><testsuite failures="0" id="137" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.codehaus.woodstox/stax2-api/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.codehaus.woodstox:stax2-api:4.2.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.codehaus.woodstox:stax2-api:4.2.1)"/></testsuite><testsuite failures="0" id="138" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.eclipse.jetty.websocket/websocket-api/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.eclipse.jetty.websocket:websocket-api:9.4.40.v20210413)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.eclipse.jetty.websocket:websocket-api:9.4.40.v20210413)"/></testsuite><testsuite failures="2" id="139" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.eclipse.jetty/jetty-xml/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.eclipse.jetty:jetty-xml:9.4.40.v20210413)" skipped="0" tests="2" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2021-28169" name="pkg:maven/org.eclipse.jetty/jetty-xml@9.4.40.v20210413"><failure message="cvssV3: MEDIUM, score: 5.3 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:L/I:N/A:N)"/><system-out>For Eclipse Jetty versions &lt;= 9.4.40, &lt;= 10.0.2, &lt;= 11.0.2, it is possible for requests to the ConcatServlet with a doubly encoded path to access protected resources within the WEB-INF directory. For example a request to `/concat?/%2557EB-INF/web.xml` can retrieve the web.xml file. This can reveal sensitive information regarding the implementation of a web application.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.eclipse.jetty/jetty-xml/pom.xml</system-err></testcase><testcase classname="CVE-2021-34428" name="pkg:maven/org.eclipse.jetty/jetty-xml@9.4.40.v20210413"><failure message="cvssV3: LOW, score: 3.5 (CVSS:3.1/AV:P/AC:L/PR:N/UI:N/S:U/C:L/I:L/A:N)"/><system-out>For Eclipse Jetty versions &lt;= 9.4.40, &lt;= 10.0.2, &lt;= 11.0.2, if an exception is thrown from the SessionListener#sessionDestroyed() method, then the session ID is not invalidated in the session ID manager. On deployments with clustered sessions and multiple contexts this can result in a session not being invalidated. This can result in an application used on a shared computer being left logged in.</system-out><system-err>location: /root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.eclipse.jetty/jetty-xml/pom.xml</system-err></testcase></testsuite><testsuite failures="0" id="140" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-builtins/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-builtins:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-builtins:3.9.0)"/></testsuite><testsuite failures="0" id="141" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-reader/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-reader:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-reader:3.9.0)"/></testsuite><testsuite failures="0" id="142" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-remote-ssh/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-remote-ssh:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-remote-ssh:3.9.0)"/></testsuite><testsuite failures="0" id="143" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-remote-telnet/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-remote-telnet:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-remote-telnet:3.9.0)"/></testsuite><testsuite failures="0" id="144" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-style/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-style:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-style:3.9.0)"/></testsuite><testsuite failures="0" id="145" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-terminal-jansi/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-terminal-jansi:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-terminal-jansi:3.9.0)"/></testsuite><testsuite failures="0" id="146" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-terminal-jna/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-terminal-jna:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-terminal-jna:3.9.0)"/></testsuite><testsuite failures="0" id="147" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline-terminal/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-terminal:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline-terminal:3.9.0)"/></testsuite><testsuite failures="0" id="148" name="/root/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.1/hadoop-client-runtime-3.3.1.jar/META-INF/maven/org.jline/jline/pom.xml" package="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline:3.9.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hadoop-client-runtime-3.3.1.jar (shaded: org.jline:jline:3.9.0)"/></testsuite><testsuite failures="0" id="149" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/historypage-common.js" package="historypage-common.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="historypage-common.js"/></testsuite><testsuite failures="0" id="150" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/historypage.js" package="historypage.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="historypage.js"/></testsuite><testsuite failures="0" id="151" name="/root/.m2/repository/org/apache/hive/hive-exec/2.3.9/hive-exec-2.3.9-core.jar" package="hive-exec-2.3.9-core.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hive-exec-2.3.9-core.jar"/></testsuite><testsuite failures="0" id="152" name="/root/.m2/repository/org/apache/hive/hive-storage-api/2.7.2/hive-storage-api-2.7.2.jar" package="hive-storage-api-2.7.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hive-storage-api-2.7.2.jar"/></testsuite><testsuite failures="0" id="153" name="/root/.m2/repository/org/glassfish/hk2/hk2-api/2.6.1/hk2-api-2.6.1.jar" package="hk2-api-2.6.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hk2-api-2.6.1.jar"/></testsuite><testsuite failures="0" id="154" name="/root/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar" package="hk2-locator-2.6.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hk2-locator-2.6.1.jar"/></testsuite><testsuite failures="0" id="155" name="/root/.m2/repository/org/glassfish/hk2/hk2-utils/2.6.1/hk2-utils-2.6.1.jar" package="hk2-utils-2.6.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="hk2-utils-2.6.1.jar"/></testsuite><testsuite failures="0" id="156" name="/root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar" package="htrace-core4-4.1.0-incubating.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="htrace-core4-4.1.0-incubating.jar"/></testsuite><testsuite failures="1" id="157" name="/root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-core/pom.xml" package="htrace-core4-4.1.0-incubating.jar (shaded: com.fasterxml.jackson.core:jackson-core:2.4.0)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-1000873" name="pkg:maven/com.fasterxml.jackson.core/jackson-core@2.4.0"><failure message="cvssV3: MEDIUM, score: 6.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H)"/><system-out>Fasterxml Jackson version Before 2.9.8 contains a CWE-20: Improper Input Validation vulnerability in Jackson-Modules-Java8 that can result in Causes a denial-of-service (DoS). This attack appear to be exploitable via The victim deserializes malicious input, specifically very large values in the nanoseconds field of a time value. This vulnerability appears to have been fixed in 2.9.8.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-core/pom.xml</system-err></testcase></testsuite><testsuite failures="19" id="158" name="/root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml" package="htrace-core4-4.1.0-incubating.jar (shaded: com.fasterxml.jackson.core:jackson-databind:2.4.0)" skipped="0" tests="19" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2017-15095" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A deserialization flaw was discovered in the jackson-databind in versions before 2.8.10 and 2.9.1, which could allow an unauthenticated user to perform code execution by sending the maliciously crafted input to the readValue method of the ObjectMapper. This issue extends the previous flaw CVE-2017-7525 by blacklisting more classes that could be used maliciously.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2017-17485" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind through 2.8.10 and 2.9.x through 2.9.3 allows unauthenticated remote code execution because of an incomplete fix for the CVE-2017-7525 deserialization flaw. This is exploitable by sending maliciously crafted JSON input to the readValue method of the ObjectMapper, bypassing a blacklist that is ineffective if the Spring libraries are available in the classpath.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2017-7525" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A deserialization flaw was discovered in the jackson-databind, versions before 2.6.7.1, 2.7.9.1 and 2.8.9, which could allow an unauthenticated user to perform code execution by sending the maliciously crafted input to the readValue method of the ObjectMapper.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2018-1000873" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: MEDIUM, score: 6.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H)"/><system-out>Fasterxml Jackson version Before 2.9.8 contains a CWE-20: Improper Input Validation vulnerability in Jackson-Modules-Java8 that can result in Causes a denial-of-service (DoS). This attack appear to be exploitable via The victim deserializes malicious input, specifically very large values in the nanoseconds field of a time value. This vulnerability appears to have been fixed in 2.9.8.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2018-11307" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>An issue was discovered in FasterXML jackson-databind 2.0.0 through 2.9.5. Use of Jackson default typing along with a gadget class from iBatis allows exfiltration of content. Fixed in 2.7.9.4, 2.8.11.2, and 2.9.6.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2018-14718" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind 2.x before 2.9.7 might allow remote attackers to execute arbitrary code by leveraging failure to block the slf4j-ext class from polymorphic deserialization.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2018-5968" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: HIGH, score: 8.1 (CVSS:/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind through 2.8.11 and 2.9.x through 2.9.3 allows unauthenticated remote code execution because of an incomplete fix for the CVE-2017-7525 and CVE-2017-17485 deserialization flaws. This is exploitable via two different gadgets that bypass a blacklist.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2018-7489" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind before 2.7.9.3, 2.8.x before 2.8.11.1 and 2.9.x before 2.9.5 allows unauthenticated remote code execution because of an incomplete fix for the CVE-2017-7525 deserialization flaw. This is exploitable by sending maliciously crafted JSON input to the readValue method of the ObjectMapper, bypassing a blacklist that is ineffective if the c3p0 libraries are available in the classpath.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-14540" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind before 2.9.10. It is related to com.zaxxer.hikari.HikariConfig.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-14893" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A flaw was discovered in FasterXML jackson-databind in all versions before 2.9.10 and 2.10.0, where it would permit polymorphic deserialization of malicious objects using the xalan JNDI gadget when used in conjunction with polymorphic type handling methods such as `enableDefaultTyping()` or when @JsonTypeInfo is using `Id.CLASS` or `Id.MINIMAL_CLASS` or in any other way which ObjectMapper.readValue might instantiate objects from unsafe sources. An attacker could use this flaw to execute arbitrary code.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-16335" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind before 2.9.10. It is related to com.zaxxer.hikari.HikariDataSource. This is a different vulnerability than CVE-2019-14540.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-16942" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind 2.0.0 through 2.9.10. When Default Typing is enabled (either globally or for a specific property) for an externally exposed JSON endpoint and the service has the commons-dbcp (1.4) jar in the classpath, and an attacker can find an RMI service endpoint to access, it is possible to make the service execute a malicious payload. This issue exists because of org.apache.commons.dbcp.datasources.SharedPoolDataSource and org.apache.commons.dbcp.datasources.PerUserPoolDataSource mishandling.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-16943" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind 2.0.0 through 2.9.10. When Default Typing is enabled (either globally or for a specific property) for an externally exposed JSON endpoint and the service has the p6spy (3.8.6) jar in the classpath, and an attacker can find an RMI service endpoint to access, it is possible to make the service execute a malicious payload. This issue exists because of com.p6spy.engine.spy.P6DataSource mishandling.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-17267" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind before 2.9.10. It is related to net.sf.ehcache.hibernate.EhcacheJtaTransactionManagerLookup.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-17531" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind 2.0.0 through 2.9.10. When Default Typing is enabled (either globally or for a specific property) for an externally exposed JSON endpoint and the service has the apache-log4j-extra (version 1.2.x) jar in the classpath, and an attacker can provide a JNDI service to access, it is possible to make the service execute a malicious payload.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2019-20330" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind 2.x before 2.9.10.2 lacks certain net.sf.ehcache blocking.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2020-35490" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: HIGH, score: 8.1 (CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind 2.x before 2.9.10.8 mishandles the interaction between serialization gadgets and typing, related to org.apache.commons.dbcp2.datasources.PerUserPoolDataSource.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CVE-2020-35491" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: HIGH, score: 8.1 (CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind 2.x before 2.9.10.8 mishandles the interaction between serialization gadgets and typing, related to org.apache.commons.dbcp2.datasources.SharedPoolDataSource.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase><testcase classname="CWE-611: Improper Restriction of XML External Entity Reference (&apos;XXE&apos;)" name="pkg:maven/com.fasterxml.jackson.core/jackson-databind@2.4.0"><failure message="cvssV3: MEDIUM, score: 5.4 (CVSS:/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>The software processes an XML document that can contain XML entities with URIs that resolve to documents outside of the intended sphere of control, causing the product to embed incorrect documents into its output.</system-out><system-err>location: /root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml</system-err></testcase></testsuite><testsuite failures="0" id="159" name="/root/.m2/repository/org/apache/htrace/htrace-core4/4.1.0-incubating/htrace-core4-4.1.0-incubating.jar/META-INF/maven/commons-logging/commons-logging/pom.xml" package="htrace-core4-4.1.0-incubating.jar (shaded: commons-logging:commons-logging:1.1.1)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="htrace-core4-4.1.0-incubating.jar (shaded: commons-logging:commons-logging:1.1.1)"/></testsuite><testsuite failures="0" id="160" name="/root/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar" package="httpclient-4.5.13.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="httpclient-4.5.13.jar"/></testsuite><testsuite failures="0" id="161" name="/root/.m2/repository/org/apache/httpcomponents/httpcore/4.4.14/httpcore-4.4.14.jar" package="httpcore-4.4.14.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="httpcore-4.4.14.jar"/></testsuite><testsuite failures="0" id="162" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/initialize-tooltips.js" package="initialize-tooltips.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="initialize-tooltips.js"/></testsuite><testsuite failures="0" id="163" name="/root/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.8/istack-commons-runtime-3.0.8.jar" package="istack-commons-runtime-3.0.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="istack-commons-runtime-3.0.8.jar"/></testsuite><testsuite failures="0" id="164" name="/root/.m2/repository/org/apache/ivy/ivy/2.5.0/ivy-2.5.0.jar" package="ivy-2.5.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="ivy-2.5.0.jar"/></testsuite><testsuite failures="0" id="165" name="/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.12.3/jackson-core-2.12.3.jar" package="jackson-core-2.12.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jackson-core-2.12.3.jar"/></testsuite><testsuite failures="0" id="166" name="/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar" package="jackson-core-asl-1.9.13.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jackson-core-asl-1.9.13.jar"/></testsuite><testsuite failures="0" id="167" name="/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.12.3/jackson-databind-2.12.3.jar" package="jackson-databind-2.12.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jackson-databind-2.12.3.jar"/></testsuite><testsuite failures="12" id="168" name="/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar" package="jackson-mapper-asl-1.9.13.jar" skipped="0" tests="12" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2017-15095" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A deserialization flaw was discovered in the jackson-databind in versions before 2.8.10 and 2.9.1, which could allow an unauthenticated user to perform code execution by sending the maliciously crafted input to the readValue method of the ObjectMapper. This issue extends the previous flaw CVE-2017-7525 by blacklisting more classes that could be used maliciously.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2017-17485" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind through 2.8.10 and 2.9.x through 2.9.3 allows unauthenticated remote code execution because of an incomplete fix for the CVE-2017-7525 deserialization flaw. This is exploitable by sending maliciously crafted JSON input to the readValue method of the ObjectMapper, bypassing a blacklist that is ineffective if the Spring libraries are available in the classpath.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2017-7525" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A deserialization flaw was discovered in the jackson-databind, versions before 2.6.7.1, 2.7.9.1 and 2.8.9, which could allow an unauthenticated user to perform code execution by sending the maliciously crafted input to the readValue method of the ObjectMapper.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2018-1000873" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: MEDIUM, score: 6.5 (CVSS:/AV:N/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H)"/><system-out>Fasterxml Jackson version Before 2.9.8 contains a CWE-20: Improper Input Validation vulnerability in Jackson-Modules-Java8 that can result in Causes a denial-of-service (DoS). This attack appear to be exploitable via The victim deserializes malicious input, specifically very large values in the nanoseconds field of a time value. This vulnerability appears to have been fixed in 2.9.8.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2018-14718" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind 2.x before 2.9.7 might allow remote attackers to execute arbitrary code by leveraging failure to block the slf4j-ext class from polymorphic deserialization.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2018-5968" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: HIGH, score: 8.1 (CVSS:/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind through 2.8.11 and 2.9.x through 2.9.3 allows unauthenticated remote code execution because of an incomplete fix for the CVE-2017-7525 and CVE-2017-17485 deserialization flaws. This is exploitable via two different gadgets that bypass a blacklist.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2018-7489" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>FasterXML jackson-databind before 2.7.9.3, 2.8.x before 2.8.11.1 and 2.9.x before 2.9.5 allows unauthenticated remote code execution because of an incomplete fix for the CVE-2017-7525 deserialization flaw. This is exploitable by sending maliciously crafted JSON input to the readValue method of the ObjectMapper, bypassing a blacklist that is ineffective if the c3p0 libraries are available in the classpath.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2019-10172" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N)"/><system-out>A flaw was found in org.codehaus.jackson:jackson-mapper-asl:1.9.x libraries. XML external entity vulnerabilities similar CVE-2016-3720 also affects codehaus jackson-mapper-asl libraries but in different classes.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2019-14540" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind before 2.9.10. It is related to com.zaxxer.hikari.HikariConfig.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2019-14893" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A flaw was discovered in FasterXML jackson-databind in all versions before 2.9.10 and 2.10.0, where it would permit polymorphic deserialization of malicious objects using the xalan JNDI gadget when used in conjunction with polymorphic type handling methods such as `enableDefaultTyping()` or when @JsonTypeInfo is using `Id.CLASS` or `Id.MINIMAL_CLASS` or in any other way which ObjectMapper.readValue might instantiate objects from unsafe sources. An attacker could use this flaw to execute arbitrary code.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2019-16335" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind before 2.9.10. It is related to com.zaxxer.hikari.HikariDataSource. This is a different vulnerability than CVE-2019-14540.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase><testcase classname="CVE-2019-17267" name="pkg:maven/org.codehaus.jackson/jackson-mapper-asl@1.9.13"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>A Polymorphic Typing issue was discovered in FasterXML jackson-databind before 2.9.10. It is related to net.sf.ehcache.hibernate.EhcacheJtaTransactionManagerLookup.</system-out><system-err>location: /root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar</system-err></testcase></testsuite><testsuite failures="0" id="169" name="/root/.m2/repository/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.12.3/jackson-module-scala_2.12-2.12.3.jar" package="jackson-module-scala_2.12-2.12.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jackson-module-scala_2.12-2.12.3.jar"/></testsuite><testsuite failures="0" id="170" name="/root/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar" package="jakarta.annotation-api-1.3.5.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jakarta.annotation-api-1.3.5.jar"/></testsuite><testsuite failures="0" id="171" name="/root/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar" package="jakarta.inject-2.6.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jakarta.inject-2.6.1.jar"/></testsuite><testsuite failures="0" id="172" name="/root/.m2/repository/jakarta/servlet/jakarta.servlet-api/4.0.3/jakarta.servlet-api-4.0.3.jar" package="jakarta.servlet-api-4.0.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jakarta.servlet-api-4.0.3.jar"/></testsuite><testsuite failures="0" id="173" name="/root/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar" package="jakarta.validation-api-2.0.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jakarta.validation-api-2.0.2.jar"/></testsuite><testsuite failures="0" id="174" name="/root/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar" package="jakarta.ws.rs-api-2.1.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jakarta.ws.rs-api-2.1.6.jar"/></testsuite><testsuite failures="0" id="175" name="/root/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.2/jakarta.xml.bind-api-2.3.2.jar" package="jakarta.xml.bind-api-2.3.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jakarta.xml.bind-api-2.3.2.jar"/></testsuite><testsuite failures="0" id="176" name="/root/.m2/repository/org/codehaus/janino/janino/3.1.4/janino-3.1.4.jar" package="janino-3.1.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="janino-3.1.4.jar"/></testsuite><testsuite failures="0" id="177" name="/root/.m2/repository/org/javassist/javassist/3.25.0-GA/javassist-3.25.0-GA.jar" package="javassist-3.25.0-GA.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="javassist-3.25.0-GA.jar"/></testsuite><testsuite failures="0" id="178" name="/root/.m2/repository/javax/annotation/javax.annotation-api/1.3.2/javax.annotation-api-1.3.2.jar" package="javax.annotation-api-1.3.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="javax.annotation-api-1.3.2.jar"/></testsuite><testsuite failures="0" id="179" name="/root/.m2/repository/org/datanucleus/javax.jdo/3.2.0-m3/javax.jdo-3.2.0-m3.jar" package="javax.jdo-3.2.0-m3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="javax.jdo-3.2.0-m3.jar"/></testsuite><testsuite failures="0" id="180" name="/root/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar" package="javax.servlet-api-3.1.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="javax.servlet-api-3.1.0.jar"/></testsuite><testsuite failures="0" id="181" name="/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar" package="javolution-5.5.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="javolution-5.5.1.jar"/></testsuite><testsuite failures="0" id="182" name="/root/.m2/repository/javax/xml/bind/jaxb-api/2.2.11/jaxb-api-2.2.11.jar" package="jaxb-api-2.2.11.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jaxb-api-2.2.11.jar"/></testsuite><testsuite failures="0" id="183" name="/root/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.2/jaxb-runtime-2.3.2.jar" package="jaxb-runtime-2.3.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jaxb-runtime-2.3.2.jar"/></testsuite><testsuite failures="0" id="184" name="/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.30/jcl-over-slf4j-1.7.30.jar" package="jcl-over-slf4j-1.7.30.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jcl-over-slf4j-1.7.30.jar"/></testsuite><testsuite failures="0" id="185" name="/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar" package="jdo-api-3.0.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jdo-api-3.0.1.jar"/></testsuite><testsuite failures="0" id="186" name="/root/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar" package="jersey-server-2.34.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jersey-server-2.34.jar"/></testsuite><testsuite failures="0" id="187" name="/root/.m2/repository/org/eclipse/jetty/jetty-io/9.4.40.v20210413/jetty-io-9.4.40.v20210413.jar" package="jetty-io-9.4.40.v20210413.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jetty-io-9.4.40.v20210413.jar"/></testsuite><testsuite failures="0" id="188" name="/root/.m2/repository/org/eclipse/jetty/jetty-io/9.4.42.v20210604/jetty-io-9.4.42.v20210604.jar" package="jetty-io-9.4.42.v20210604.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jetty-io-9.4.42.v20210604.jar"/></testsuite><testsuite failures="0" id="189" name="/root/.m2/repository/org/eclipse/jetty/jetty-server/9.4.42.v20210604/jetty-server-9.4.42.v20210604.jar" package="jetty-server-9.4.42.v20210604.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jetty-server-9.4.42.v20210604.jar"/></testsuite><testsuite failures="0" id="190" name="/root/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.42.v20210604/jetty-xml-9.4.42.v20210604.jar" package="jetty-xml-9.4.42.v20210604.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jetty-xml-9.4.42.v20210604.jar"/></testsuite><testsuite failures="0" id="191" name="/root/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar" package="jline-2.14.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jline-2.14.6.jar"/></testsuite><testsuite failures="0" id="192" name="/root/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar/META-INF/native/windows64/jansi.dll" package="jline-2.14.6.jar: jansi.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jline-2.14.6.jar: jansi.dll"/></testsuite><testsuite failures="0" id="193" name="/root/.m2/repository/jline/jline/2.14.6/jline-2.14.6.jar/META-INF/native/windows32/jansi.dll" package="jline-2.14.6.jar: jansi.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jline-2.14.6.jar: jansi.dll"/></testsuite><testsuite failures="0" id="194" name="/root/.m2/repository/joda-time/joda-time/2.10.10/joda-time-2.10.10.jar" package="joda-time-2.10.10.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="joda-time-2.10.10.jar"/></testsuite><testsuite failures="1" id="195" name="/root/.m2/repository/org/jodd/jodd-core/3.5.2/jodd-core-3.5.2.jar" package="jodd-core-3.5.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-21234" name="pkg:maven/org.jodd/jodd-core@3.5.2"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>Jodd before 5.0.4 performs Deserialization of Untrusted JSON Data when setClassMetadataName is set.</system-out><system-err>location: /root/.m2/repository/org/jodd/jodd-core/3.5.2/jodd-core-3.5.2.jar</system-err></testcase></testsuite><testsuite failures="0" id="196" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/jquery-3.5.1.min.js" package="jquery-3.5.1.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jquery-3.5.1.min.js"/></testsuite><testsuite failures="0" id="197" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/jquery.blockUI.min.js" package="jquery.blockUI.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jquery.blockUI.min.js"/></testsuite><testsuite failures="0" id="198" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/jquery.cookies.2.2.0.min.js" package="jquery.cookies.2.2.0.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jquery.cookies.2.2.0.min.js"/></testsuite><testsuite failures="0" id="199" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/jquery.dataTables.1.10.20.min.js" package="jquery.dataTables.1.10.20.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jquery.dataTables.1.10.20.min.js"/></testsuite><testsuite failures="0" id="200" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/jquery.mustache.js" package="jquery.mustache.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jquery.mustache.js"/></testsuite><testsuite failures="0" id="201" name="/root/.m2/repository/com/tdunning/json/1.8/json-1.8.jar" package="json-1.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="json-1.8.jar"/></testsuite><testsuite failures="0" id="202" name="/root/.m2/repository/org/json4s/json4s-ast_2.12/3.7.0-M11/json4s-ast_2.12-3.7.0-M11.jar" package="json4s-ast_2.12-3.7.0-M11.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="json4s-ast_2.12-3.7.0-M11.jar"/></testsuite><testsuite failures="0" id="203" name="/root/.m2/repository/org/json4s/json4s-core_2.12/3.7.0-M11/json4s-core_2.12-3.7.0-M11.jar" package="json4s-core_2.12-3.7.0-M11.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="json4s-core_2.12-3.7.0-M11.jar"/></testsuite><testsuite failures="0" id="204" name="/root/.m2/repository/org/json4s/json4s-jackson_2.12/3.7.0-M11/json4s-jackson_2.12-3.7.0-M11.jar" package="json4s-jackson_2.12-3.7.0-M11.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="json4s-jackson_2.12-3.7.0-M11.jar"/></testsuite><testsuite failures="0" id="205" name="/root/.m2/repository/org/json4s/json4s-scalap_2.12/3.7.0-M11/json4s-scalap_2.12-3.7.0-M11.jar" package="json4s-scalap_2.12-3.7.0-M11.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="json4s-scalap_2.12-3.7.0-M11.jar"/></testsuite><testsuite failures="0" id="206" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/jsonFormatter.min.js" package="jsonFormatter.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jsonFormatter.min.js"/></testsuite><testsuite failures="0" id="207" name="/root/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar" package="jsr305-3.0.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jsr305-3.0.0.jar"/></testsuite><testsuite failures="0" id="208" name="/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar" package="jta-1.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jta-1.1.jar"/></testsuite><testsuite failures="0" id="209" name="/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.30/jul-to-slf4j-1.7.30.jar" package="jul-to-slf4j-1.7.30.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="jul-to-slf4j-1.7.30.jar"/></testsuite><testsuite failures="0" id="210" name="/root/.m2/repository/org/apache/kafka/kafka-clients/2.8.0/kafka-clients-2.8.0.jar" package="kafka-clients-2.8.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="kafka-clients-2.8.0.jar"/></testsuite><testsuite failures="0" id="211" name="/root/.m2/repository/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar" package="kryo-shaded-4.0.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="kryo-shaded-4.0.2.jar"/></testsuite><testsuite failures="0" id="212" name="/root/.m2/repository/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar/META-INF/maven/com.esotericsoftware/reflectasm/pom.xml" package="kryo-shaded-4.0.2.jar (shaded: com.esotericsoftware:reflectasm:1.11.3)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="kryo-shaded-4.0.2.jar (shaded: com.esotericsoftware:reflectasm:1.11.3)"/></testsuite><testsuite failures="0" id="213" name="/root/.m2/repository/dev/ludovic/netlib/lapack/2.2.0/lapack-2.2.0.jar" package="lapack-2.2.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="lapack-2.2.0.jar"/></testsuite><testsuite failures="0" id="214" name="/root/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar" package="leveldbjni-all-1.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="leveldbjni-all-1.8.jar"/></testsuite><testsuite failures="0" id="215" name="/root/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar/META-INF/native/windows64/leveldbjni.dll" package="leveldbjni-all-1.8.jar: leveldbjni.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="leveldbjni-all-1.8.jar: leveldbjni.dll"/></testsuite><testsuite failures="0" id="216" name="/root/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar/META-INF/native/windows32/leveldbjni.dll" package="leveldbjni-all-1.8.jar: leveldbjni.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="leveldbjni-all-1.8.jar: leveldbjni.dll"/></testsuite><testsuite failures="6" id="217" name="/root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar" package="libfb303-0.9.3.jar" skipped="0" tests="6" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2016-5397" name="pkg:maven/org.apache.thrift/libfb303@0.9.3"><failure message="cvssV3: HIGH, score: 8.8 (CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)"/><system-out>The Apache Thrift Go client library exposed the potential during code generation for command injection due to using an external formatting tool. Affected Apache Thrift 0.9.3 and older, Fixed in Apache Thrift 0.10.0.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</system-err></testcase><testcase classname="CVE-2018-11798" name="pkg:maven/org.apache.thrift/libfb303@0.9.3"><failure message="cvssV3: MEDIUM, score: 6.5 (CVSS:3.0/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N)"/><system-out>The Apache Thrift Node.js static web server in versions 0.9.2 through 0.11.0 have been determined to contain a security vulnerability in which a remote user has the ability to access files outside the set webservers docroot path.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</system-err></testcase><testcase classname="CVE-2018-1320" name="pkg:maven/org.apache.thrift/libfb303@0.9.3"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:N)"/><system-out>Apache Thrift Java client library versions 0.5.0 through 0.11.0 can bypass SASL negotiation isComplete validation in the org.apache.thrift.transport.TSaslTransport class. An assert used to determine if the SASL handshake had successfully completed could be disabled in production settings making the validation incomplete.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</system-err></testcase><testcase classname="CVE-2019-0205" name="pkg:maven/org.apache.thrift/libfb303@0.9.3"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>In Apache Thrift all versions up to and including 0.12.0, a server or client may run into an endless loop when feed with specific input data. Because the issue had already been partially fixed in version 0.11.0, depending on the installed version it affects only certain language bindings.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</system-err></testcase><testcase classname="CVE-2019-0210" name="pkg:maven/org.apache.thrift/libfb303@0.9.3"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>In Apache Thrift 0.9.3 to 0.12.0, a server implemented in Go using TJSONProtocol or TSimpleJSONProtocol may panic when feed with invalid input data.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</system-err></testcase><testcase classname="CVE-2020-13949" name="pkg:maven/org.apache.thrift/libfb303@0.9.3"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>In Apache Thrift 0.9.3 to 0.13.0, malicious RPC clients could send short messages which would result in a large memory allocation, potentially leading to denial of service.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libfb303/0.9.3/libfb303-0.9.3.jar</system-err></testcase></testsuite><testsuite failures="3" id="218" name="/root/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar" package="libthrift-0.12.0.jar" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2019-0205" name="pkg:maven/org.apache.thrift/libthrift@0.12.0"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>In Apache Thrift all versions up to and including 0.12.0, a server or client may run into an endless loop when feed with specific input data. Because the issue had already been partially fixed in version 0.11.0, depending on the installed version it affects only certain language bindings.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar</system-err></testcase><testcase classname="CVE-2019-0210" name="pkg:maven/org.apache.thrift/libthrift@0.12.0"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>In Apache Thrift 0.9.3 to 0.12.0, a server implemented in Go using TJSONProtocol or TSimpleJSONProtocol may panic when feed with invalid input data.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar</system-err></testcase><testcase classname="CVE-2020-13949" name="pkg:maven/org.apache.thrift/libthrift@0.12.0"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H)"/><system-out>In Apache Thrift 0.9.3 to 0.13.0, malicious RPC clients could send short messages which would result in a large memory allocation, potentially leading to denial of service.</system-out><system-err>location: /root/.m2/repository/org/apache/thrift/libthrift/0.12.0/libthrift-0.12.0.jar</system-err></testcase></testsuite><testsuite failures="0" id="219" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/log-view.js" package="log-view.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="log-view.js"/></testsuite><testsuite failures="2" id="220" name="/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar" package="log4j-1.2.17.jar" skipped="0" tests="2" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2019-17571" name="pkg:maven/log4j/log4j@1.2.17"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>Included in Log4j 1.2 is a SocketServer class that is vulnerable to deserialization of untrusted data which can be exploited to remotely execute arbitrary code when combined with a deserialization gadget when listening to untrusted network traffic for log data. This affects Log4j versions up to 1.2 up to 1.2.17.</system-out><system-err>location: /root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar</system-err></testcase><testcase classname="CVE-2020-9488" name="pkg:maven/log4j/log4j@1.2.17"><failure message="cvssV3: LOW, score: 3.7 (CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:N/A:N)"/><system-out>Improper validation of certificate with host mismatch in Apache Log4j SMTP appender. This could allow an SMTPS connection to be intercepted by a man-in-the-middle attack which could leak any log messages sent through that appender.</system-out><system-err>location: /root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar</system-err></testcase></testsuite><testsuite failures="0" id="221" name="/root/.m2/repository/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar" package="lz4-java-1.7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="lz4-java-1.7.1.jar"/></testsuite><testsuite failures="0" id="222" name="/root/.m2/repository/org/typelevel/machinist_2.12/0.6.8/machinist_2.12-0.6.8.jar" package="machinist_2.12-0.6.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="machinist_2.12-0.6.8.jar"/></testsuite><testsuite failures="0" id="223" name="/root/.m2/repository/org/typelevel/macro-compat_2.12/1.1.1/macro-compat_2.12-1.1.1.jar" package="macro-compat_2.12-1.1.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="macro-compat_2.12-1.1.1.jar"/></testsuite><testsuite failures="0" id="224" name="/root/.m2/repository/io/dropwizard/metrics/metrics-core/4.2.2/metrics-core-4.2.2.jar" package="metrics-core-4.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="metrics-core-4.2.2.jar"/></testsuite><testsuite failures="0" id="225" name="/root/.m2/repository/io/dropwizard/metrics/metrics-graphite/4.2.2/metrics-graphite-4.2.2.jar" package="metrics-graphite-4.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="metrics-graphite-4.2.2.jar"/></testsuite><testsuite failures="0" id="226" name="/root/.m2/repository/io/dropwizard/metrics/metrics-jmx/4.2.2/metrics-jmx-4.2.2.jar" package="metrics-jmx-4.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="metrics-jmx-4.2.2.jar"/></testsuite><testsuite failures="0" id="227" name="/root/.m2/repository/io/dropwizard/metrics/metrics-json/4.2.2/metrics-json-4.2.2.jar" package="metrics-json-4.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="metrics-json-4.2.2.jar"/></testsuite><testsuite failures="0" id="228" name="/root/.m2/repository/io/dropwizard/metrics/metrics-jvm/4.2.2/metrics-jvm-4.2.2.jar" package="metrics-jvm-4.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="metrics-jvm-4.2.2.jar"/></testsuite><testsuite failures="0" id="229" name="/root/.m2/repository/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar" package="minlog-1.3.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="minlog-1.3.0.jar"/></testsuite><testsuite failures="0" id="230" name="/root/.m2/repository/io/netty/netty-all/4.1.63.Final/netty-all-4.1.63.Final.jar" package="netty-all-4.1.63.Final.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="netty-all-4.1.63.Final.jar"/></testsuite><testsuite failures="0" id="231" name="/root/.m2/repository/org/objenesis/objenesis/2.6/objenesis-2.6.jar" package="objenesis-2.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="objenesis-2.6.jar"/></testsuite><testsuite failures="0" id="232" name="/root/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar" package="opencsv-2.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="opencsv-2.3.jar"/></testsuite><testsuite failures="0" id="233" name="/root/.m2/repository/org/apache/orc/orc-core/1.6.9/orc-core-1.6.9.jar" package="orc-core-1.6.9.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="orc-core-1.6.9.jar"/></testsuite><testsuite failures="3" id="234" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="235" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="236" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="237" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="238" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="239" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="240" name="/root/temp2/spark/sql/catalyst/pom.xml" package="org.apache.spark:spark-catalyst_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-catalyst_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/catalyst/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="241" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="242" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="243" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="244" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="245" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="246" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="247" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="248" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="249" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="250" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="251" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="252" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="253" name="/root/temp2/spark/core/pom.xml" package="org.apache.spark:spark-core_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-core_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="254" name="/root/temp2/spark/graphx/pom.xml" package="org.apache.spark:spark-graphx_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="255" name="/root/temp2/spark/graphx/pom.xml" package="org.apache.spark:spark-graphx_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="256" name="/root/temp2/spark/graphx/pom.xml" package="org.apache.spark:spark-graphx_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-graphx_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/graphx/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="257" name="/root/temp2/spark/sql/hive/pom.xml" package="org.apache.spark:spark-hive_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-hive_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/hive/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-hive_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/hive/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-hive_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/hive/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="258" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="259" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="260" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="261" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="262" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="263" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="264" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="265" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="266" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="267" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="268" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="269" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="270" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="271" name="/root/temp2/spark/common/kvstore/pom.xml" package="org.apache.spark:spark-kvstore_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-kvstore_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/kvstore/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="272" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="273" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="274" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="275" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="276" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="277" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="278" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="279" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="280" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="281" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="282" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="283" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="284" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="285" name="/root/temp2/spark/launcher/pom.xml" package="org.apache.spark:spark-launcher_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-launcher_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/launcher/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="286" name="/root/temp2/spark/mllib-local/pom.xml" package="org.apache.spark:spark-mllib-local_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="287" name="/root/temp2/spark/mllib-local/pom.xml" package="org.apache.spark:spark-mllib-local_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="288" name="/root/temp2/spark/mllib-local/pom.xml" package="org.apache.spark:spark-mllib-local_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="289" name="/root/temp2/spark/mllib-local/pom.xml" package="org.apache.spark:spark-mllib-local_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-mllib-local_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/mllib-local/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="290" name="/root/temp2/spark/mllib/pom.xml" package="org.apache.spark:spark-mllib_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-mllib_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/mllib/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-mllib_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/mllib/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-mllib_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/mllib/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="291" name="/root/temp2/spark/mllib/pom.xml" package="org.apache.spark:spark-mllib_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-mllib_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/mllib/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-mllib_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/mllib/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-mllib_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/mllib/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="292" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="293" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="294" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="295" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="296" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="297" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="298" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="299" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="300" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="301" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="302" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="303" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="304" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="305" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="306" name="/root/temp2/spark/common/network-common/pom.xml" package="org.apache.spark:spark-network-common_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-common_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-common/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="307" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="308" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="309" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="310" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="311" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="312" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="313" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="314" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="315" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="316" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="317" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="318" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="319" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="320" name="/root/temp2/spark/common/network-shuffle/pom.xml" package="org.apache.spark:spark-network-shuffle_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-network-shuffle_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/network-shuffle/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="321" name="/root/temp2/spark/repl/pom.xml" package="org.apache.spark:spark-repl_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-repl_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/repl/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-repl_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/repl/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-repl_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/repl/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="322" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="323" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="324" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="325" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="326" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="327" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="328" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="329" name="/root/temp2/spark/common/sketch/pom.xml" package="org.apache.spark:spark-sketch_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sketch_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/sketch/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="330" name="/root/temp2/spark/external/kafka-0-10-sql/pom.xml" package="org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-sql/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-sql/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-sql/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="331" name="/root/temp2/spark/sql/core/pom.xml" package="org.apache.spark:spark-sql_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="332" name="/root/temp2/spark/sql/core/pom.xml" package="org.apache.spark:spark-sql_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="333" name="/root/temp2/spark/sql/core/pom.xml" package="org.apache.spark:spark-sql_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="334" name="/root/temp2/spark/sql/core/pom.xml" package="org.apache.spark:spark-sql_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="335" name="/root/temp2/spark/sql/core/pom.xml" package="org.apache.spark:spark-sql_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="336" name="/root/temp2/spark/sql/core/pom.xml" package="org.apache.spark:spark-sql_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-sql_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/sql/core/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="337" name="/root/temp2/spark/external/kafka-0-10/pom.xml" package="org.apache.spark:spark-streaming-kafka-0-10_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-streaming-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-streaming-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-streaming-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="338" name="/root/temp2/spark/streaming/pom.xml" package="org.apache.spark:spark-streaming_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="339" name="/root/temp2/spark/streaming/pom.xml" package="org.apache.spark:spark-streaming_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="340" name="/root/temp2/spark/streaming/pom.xml" package="org.apache.spark:spark-streaming_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="341" name="/root/temp2/spark/streaming/pom.xml" package="org.apache.spark:spark-streaming_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="342" name="/root/temp2/spark/streaming/pom.xml" package="org.apache.spark:spark-streaming_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-streaming_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/streaming/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="343" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="344" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="345" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="346" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="347" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="348" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="349" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="350" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="351" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="352" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="353" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="354" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="355" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="356" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="357" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="358" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="359" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="360" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="361" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="362" name="/root/temp2/spark/common/tags/pom.xml" package="org.apache.spark:spark-tags_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-tags_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/tags/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="363" name="/root/temp2/spark/external/kafka-0-10-token-provider/pom.xml" package="org.apache.spark:spark-token-provider-kafka-0-10_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="364" name="/root/temp2/spark/external/kafka-0-10-token-provider/pom.xml" package="org.apache.spark:spark-token-provider-kafka-0-10_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="365" name="/root/temp2/spark/external/kafka-0-10-token-provider/pom.xml" package="org.apache.spark:spark-token-provider-kafka-0-10_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-token-provider-kafka-0-10_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/external/kafka-0-10-token-provider/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="366" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="367" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="368" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="369" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="370" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="371" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="372" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="373" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="374" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="375" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="376" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="377" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="378" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="3" id="379" name="/root/temp2/spark/common/unsafe/pom.xml" package="org.apache.spark:spark-unsafe_2.12:3.3.0-SNAPSHOT" skipped="0" tests="3" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2018-11770" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: MEDIUM, score: 4.2 (CVSS:3.0/AV:N/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:N)"/><system-out>From version 1.3.0 onward, Apache Spark&apos;s standalone master exposes a REST API for job submission, in addition to the submission mechanism used by spark-submit. In standalone, the config property &apos;spark.authenticate.secret&apos; establishes a shared secret for authenticating requests to submit jobs via spark-submit. However, the REST API does not use this or any other authentication mechanism, and this is not adequately documented. In this case, a user would be able to run a driver program without authenticating, but not launch executors, using the REST API. This REST API is also used by Mesos, when set up to run in cluster mode (i.e., when also running MesosClusterDispatcher), for job submission. Future versions of Spark will improve documentation on these points, and prohibit setting &apos;spark.authenticate.secret&apos; when running the REST APIs, to make this clear. Future versions will also disable the REST API by default in the standalone master by changing the default value of &apos;spark.master.rest.enabled&apos; to &apos;false&apos;.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-11804" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: HIGH, score: 7.5 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N)"/><system-out>Spark&apos;s Apache Maven-based build includes a convenience script, &apos;build/mvn&apos;, that downloads and runs a zinc server to speed up compilation. It has been included in release branches since 1.3.x, up to and including master. This server will accept connections from external hosts by default. A specially-crafted request to the zinc server could cause it to reveal information in files readable to the developer account running the build. Note that this issue does not affect end users of Spark, only developers building Spark from source code.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.apache.spark/spark-unsafe_2.12@3.3.0-SNAPSHOT"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/temp2/spark/common/unsafe/pom.xml</system-err></testcase></testsuite><testsuite failures="0" id="380" name="/root/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar" package="oro-2.0.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="oro-2.0.8.jar"/></testsuite><testsuite failures="0" id="381" name="/root/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar" package="osgi-resource-locator-1.0.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="osgi-resource-locator-1.0.3.jar"/></testsuite><testsuite failures="0" id="382" name="/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar" package="paranamer-2.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="paranamer-2.8.jar"/></testsuite><testsuite failures="0" id="383" name="/root/.m2/repository/org/apache/parquet/parquet-column/1.12.0/parquet-column-1.12.0.jar" package="parquet-column-1.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-column-1.12.0.jar"/></testsuite><testsuite failures="0" id="384" name="/root/.m2/repository/org/apache/parquet/parquet-column/1.12.0/parquet-column-1.12.0.jar/META-INF/maven/net.openhft/zero-allocation-hashing/pom.xml" package="parquet-column-1.12.0.jar (shaded: net.openhft:zero-allocation-hashing:0.9)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-column-1.12.0.jar (shaded: net.openhft:zero-allocation-hashing:0.9)"/></testsuite><testsuite failures="0" id="385" name="/root/.m2/repository/org/apache/parquet/parquet-common/1.12.0/parquet-common-1.12.0.jar" package="parquet-common-1.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-common-1.12.0.jar"/></testsuite><testsuite failures="0" id="386" name="/root/.m2/repository/org/apache/parquet/parquet-encoding/1.12.0/parquet-encoding-1.12.0.jar" package="parquet-encoding-1.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-encoding-1.12.0.jar"/></testsuite><testsuite failures="0" id="387" name="/root/.m2/repository/org/apache/parquet/parquet-format-structures/1.12.0/parquet-format-structures-1.12.0.jar" package="parquet-format-structures-1.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-format-structures-1.12.0.jar"/></testsuite><testsuite failures="0" id="388" name="/root/.m2/repository/org/apache/parquet/parquet-hadoop/1.12.0/parquet-hadoop-1.12.0.jar" package="parquet-hadoop-1.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-hadoop-1.12.0.jar"/></testsuite><testsuite failures="0" id="389" name="/root/.m2/repository/org/apache/parquet/parquet-jackson/1.12.0/parquet-jackson-1.12.0.jar" package="parquet-jackson-1.12.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-jackson-1.12.0.jar"/></testsuite><testsuite failures="0" id="390" name="/root/.m2/repository/org/apache/parquet/parquet-jackson/1.12.0/parquet-jackson-1.12.0.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-core/pom.xml" package="parquet-jackson-1.12.0.jar (shaded: com.fasterxml.jackson.core:jackson-core:2.11.4)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-jackson-1.12.0.jar (shaded: com.fasterxml.jackson.core:jackson-core:2.11.4)"/></testsuite><testsuite failures="0" id="391" name="/root/.m2/repository/org/apache/parquet/parquet-jackson/1.12.0/parquet-jackson-1.12.0.jar/META-INF/maven/com.fasterxml.jackson.core/jackson-databind/pom.xml" package="parquet-jackson-1.12.0.jar (shaded: com.fasterxml.jackson.core:jackson-databind:2.11.4)" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="parquet-jackson-1.12.0.jar (shaded: com.fasterxml.jackson.core:jackson-databind:2.11.4)"/></testsuite><testsuite failures="0" id="392" name="/root/.m2/repository/org/jpmml/pmml-model/1.4.8/pmml-model-1.4.8.jar" package="pmml-model-1.4.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="pmml-model-1.4.8.jar"/></testsuite><testsuite failures="0" id="393" name="/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar" package="protobuf-java-2.5.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="protobuf-java-2.5.0.jar"/></testsuite><testsuite failures="0" id="394" name="/root/.m2/repository/net/sf/py4j/py4j/0.10.9.2/py4j-0.10.9.2.jar" package="py4j-0.10.9.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="py4j-0.10.9.2.jar"/></testsuite><testsuite failures="0" id="395" name="/root/.m2/repository/net/razorvine/pyrolite/4.30/pyrolite-4.30.jar" package="pyrolite-4.30.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="pyrolite-4.30.jar"/></testsuite><testsuite failures="0" id="396" name="/root/.m2/repository/org/rocksdb/rocksdbjni/6.2.2/rocksdbjni-6.2.2.jar" package="rocksdbjni-6.2.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="rocksdbjni-6.2.2.jar"/></testsuite><testsuite failures="0" id="397" name="/root/.m2/repository/org/rocksdb/rocksdbjni/6.2.2/rocksdbjni-6.2.2.jar/librocksdbjni-win64.dll" package="rocksdbjni-6.2.2.jar: librocksdbjni-win64.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="rocksdbjni-6.2.2.jar: librocksdbjni-win64.dll"/></testsuite><testsuite failures="0" id="398" name="/root/.m2/repository/org/scala-lang/modules/scala-collection-compat_2.12/2.0.0/scala-collection-compat_2.12-2.0.0.jar" package="scala-collection-compat_2.12-2.0.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-collection-compat_2.12-2.0.0.jar"/></testsuite><testsuite failures="0" id="399" name="/root/.m2/repository/org/scala-lang/modules/scala-collection-compat_2.12/2.1.1/scala-collection-compat_2.12-2.1.1.jar" package="scala-collection-compat_2.12-2.1.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-collection-compat_2.12-2.1.1.jar"/></testsuite><testsuite failures="0" id="400" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/diagrams.js" package="scala-compiler-2.12.14.jar: diagrams.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: diagrams.js"/></testsuite><testsuite failures="0" id="401" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/index.js" package="scala-compiler-2.12.14.jar: index.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: index.js"/></testsuite><testsuite failures="0" id="402" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/jquery.mousewheel.min.js" package="scala-compiler-2.12.14.jar: jquery.mousewheel.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: jquery.mousewheel.min.js"/></testsuite><testsuite failures="0" id="403" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/jquery.panzoom.min.js" package="scala-compiler-2.12.14.jar: jquery.panzoom.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: jquery.panzoom.min.js"/></testsuite><testsuite failures="0" id="404" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/jquery.slim.min.js" package="scala-compiler-2.12.14.jar: jquery.slim.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: jquery.slim.min.js"/></testsuite><testsuite failures="0" id="405" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/modernizr.custom.js" package="scala-compiler-2.12.14.jar: modernizr.custom.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: modernizr.custom.js"/></testsuite><testsuite failures="0" id="406" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/scheduler.js" package="scala-compiler-2.12.14.jar: scheduler.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: scheduler.js"/></testsuite><testsuite failures="0" id="407" name="/root/.m2/repository/org/scala-lang/scala-compiler/2.12.14/scala-compiler-2.12.14.jar/scala/tools/nsc/doc/html/resource/lib/template.js" package="scala-compiler-2.12.14.jar: template.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-compiler-2.12.14.jar: template.js"/></testsuite><testsuite failures="0" id="408" name="/root/.m2/repository/org/scala-lang/scala-library/2.12.14/scala-library-2.12.14.jar" package="scala-library-2.12.14.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-library-2.12.14.jar"/></testsuite><testsuite failures="0" id="409" name="/root/.m2/repository/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.2/scala-parser-combinators_2.12-1.1.2.jar" package="scala-parser-combinators_2.12-1.1.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-parser-combinators_2.12-1.1.2.jar"/></testsuite><testsuite failures="0" id="410" name="/root/.m2/repository/org/scala-lang/modules/scala-xml_2.12/1.2.0/scala-xml_2.12-1.2.0.jar" package="scala-xml_2.12-1.2.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scala-xml_2.12-1.2.0.jar"/></testsuite><testsuite failures="0" id="411" name="/root/.m2/repository/com/github/scopt/scopt_2.12/3.7.1/scopt_2.12-3.7.1.jar" package="scopt_2.12-3.7.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="scopt_2.12-3.7.1.jar"/></testsuite><testsuite failures="0" id="412" name="/root/.m2/repository/com/chuusai/shapeless_2.12/2.3.3/shapeless_2.12-2.3.3.jar" package="shapeless_2.12-2.3.3.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="shapeless_2.12-2.3.3.jar"/></testsuite><testsuite failures="0" id="413" name="/root/.m2/repository/org/roaringbitmap/shims/0.9.0/shims-0.9.0.jar" package="shims-0.9.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="shims-0.9.0.jar"/></testsuite><testsuite failures="0" id="414" name="/root/.m2/repository/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar" package="slf4j-api-1.7.30.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="slf4j-api-1.7.30.jar"/></testsuite><testsuite failures="0" id="415" name="/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.30/slf4j-log4j12-1.7.30.jar" package="slf4j-log4j12-1.7.30.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="slf4j-log4j12-1.7.30.jar"/></testsuite><testsuite failures="0" id="416" name="/root/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar" package="snappy-java-1.1.8.4.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="snappy-java-1.1.8.4.jar"/></testsuite><testsuite failures="0" id="417" name="/root/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar/org/xerial/snappy/native/Windows/x86_64/snappyjava.dll" package="snappy-java-1.1.8.4.jar: snappyjava.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="snappy-java-1.1.8.4.jar: snappyjava.dll"/></testsuite><testsuite failures="0" id="418" name="/root/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.4/snappy-java-1.1.8.4.jar/org/xerial/snappy/native/Windows/x86/snappyjava.dll" package="snappy-java-1.1.8.4.jar: snappyjava.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="snappy-java-1.1.8.4.jar: snappyjava.dll"/></testsuite><testsuite failures="0" id="419" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/sorttable.js" package="sorttable.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="sorttable.js"/></testsuite><testsuite failures="0" id="420" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/spark-dag-viz.js" package="spark-dag-viz.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="spark-dag-viz.js"/></testsuite><testsuite failures="0" id="421" name="/root/temp2/spark/sql/core/src/main/resources/org/apache/spark/sql/execution/ui/static/spark-sql-viz.js" package="spark-sql-viz.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="spark-sql-viz.js"/></testsuite><testsuite failures="0" id="422" name="/root/.m2/repository/org/typelevel/spire-macros_2.12/0.17.0-M1/spire-macros_2.12-0.17.0-M1.jar" package="spire-macros_2.12-0.17.0-M1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="spire-macros_2.12-0.17.0-M1.jar"/></testsuite><testsuite failures="0" id="423" name="/root/.m2/repository/org/typelevel/spire-platform_2.12/0.17.0-M1/spire-platform_2.12-0.17.0-M1.jar" package="spire-platform_2.12-0.17.0-M1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="spire-platform_2.12-0.17.0-M1.jar"/></testsuite><testsuite failures="0" id="424" name="/root/.m2/repository/org/typelevel/spire-util_2.12/0.17.0-M1/spire-util_2.12-0.17.0-M1.jar" package="spire-util_2.12-0.17.0-M1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="spire-util_2.12-0.17.0-M1.jar"/></testsuite><testsuite failures="0" id="425" name="/root/.m2/repository/org/typelevel/spire_2.12/0.17.0-M1/spire_2.12-0.17.0-M1.jar" package="spire_2.12-0.17.0-M1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="spire_2.12-0.17.0-M1.jar"/></testsuite><testsuite failures="0" id="426" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/stagepage.js" package="stagepage.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="stagepage.js"/></testsuite><testsuite failures="0" id="427" name="/root/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar" package="stax-api-1.0.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="stax-api-1.0.1.jar"/></testsuite><testsuite failures="0" id="428" name="/root/.m2/repository/com/clearspring/analytics/stream/2.9.6/stream-2.9.6.jar" package="stream-2.9.6.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="stream-2.9.6.jar"/></testsuite><testsuite failures="0" id="429" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/streaming-page.js" package="streaming-page.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="streaming-page.js"/></testsuite><testsuite failures="0" id="430" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/structured-streaming-page.js" package="structured-streaming-page.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="structured-streaming-page.js"/></testsuite><testsuite failures="0" id="431" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/table.js" package="table.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="table.js"/></testsuite><testsuite failures="0" id="432" name="/root/.m2/repository/org/threeten/threeten-extra/1.5.0/threeten-extra-1.5.0.jar" package="threeten-extra-1.5.0.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="threeten-extra-1.5.0.jar"/></testsuite><testsuite failures="0" id="433" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/timeline-view.js" package="timeline-view.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="timeline-view.js"/></testsuite><testsuite failures="0" id="434" name="/root/.m2/repository/com/univocity/univocity-parsers/2.9.1/univocity-parsers-2.9.1.jar" package="univocity-parsers-2.9.1.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="univocity-parsers-2.9.1.jar"/></testsuite><testsuite failures="4" id="435" name="/root/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar" package="unused-1.0.0.jar" skipped="0" tests="4" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2017-7678" name="pkg:maven/org.spark-project.spark/unused@1.0.0"><failure message="cvssV3: MEDIUM, score: 6.1 (CVSS:3.0/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N)"/><system-out>In Apache Spark before 2.2.0, it is possible for an attacker to take advantage of a user&apos;s trust in the server to trick them into visiting a link that points to a shared Spark cluster and submits data including MHTML to the Spark master, or history server. This data, which could contain a script, would then be reflected back to the user and could be evaluated and executed by MS Windows-based clients. It is not an attack on Spark itself, but on the user, who may then execute the script inadvertently when viewing elements of the Spark web UIs.</system-out><system-err>location: /root/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar</system-err></testcase><testcase classname="CVE-2018-1334" name="pkg:maven/org.spark-project.spark/unused@1.0.0"><failure message="cvssV3: MEDIUM, score: 4.7 (CVSS:3.0/AV:L/AC:H/PR:L/UI:N/S:U/C:N/I:H/A:N)"/><system-out>In Apache Spark 1.0.0 to 2.1.2, 2.2.0 to 2.2.1, and 2.3.0, when using PySpark or SparkR, it&apos;s possible for a different local user to connect to the Spark application and impersonate the user running the Spark application.</system-out><system-err>location: /root/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar</system-err></testcase><testcase classname="CVE-2018-17190" name="pkg:maven/org.spark-project.spark/unused@1.0.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In all versions of Apache Spark, its standalone resource manager accepts code to execute on a &apos;master&apos; host, that then runs that code on &apos;worker&apos; hosts. The master itself does not, by design, execute user code. A specially-crafted request to the master can, however, cause the master to execute code too. Note that this does not affect standalone clusters with authentication enabled. While the master host typically has less outbound access to other resources than a worker, the execution of code on the master is nevertheless unexpected.</system-out><system-err>location: /root/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar</system-err></testcase><testcase classname="CVE-2020-9480" name="pkg:maven/org.spark-project.spark/unused@1.0.0"><failure message="cvssV3: CRITICAL, score: 9.8 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H)"/><system-out>In Apache Spark 2.4.5 and earlier, a standalone resource manager&apos;s master may be configured to require authentication (spark.authenticate) via a shared secret. When enabled, however, a specially-crafted RPC to the master can succeed in starting an application&apos;s resources on the Spark cluster, even without the shared key. This can be leveraged to execute shell commands on the host machine. This does not affect Spark clusters using other resource managers (YARN, Mesos, etc).</system-out><system-err>location: /root/.m2/repository/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar</system-err></testcase></testsuite><testsuite failures="0" id="436" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/utils.js" package="utils.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="utils.js"/></testsuite><testsuite failures="1" id="437" name="/root/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar" package="velocity-1.5.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2020-13936" name="pkg:maven/org.apache.velocity/velocity@1.5"><failure message="cvssV3: HIGH, score: 8.8 (CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H)"/><system-out>An attacker that is able to modify Velocity templates may execute arbitrary Java code or run arbitrary system commands with the same privileges as the account running the Servlet container. This applies to applications that allow untrusted users to upload/modify velocity templates running Apache Velocity Engine versions up to 2.2.</system-out><system-err>location: /root/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar</system-err></testcase></testsuite><testsuite failures="0" id="438" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/vis-timeline-graph2d.min.js" package="vis-timeline-graph2d.min.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="vis-timeline-graph2d.min.js"/></testsuite><testsuite failures="0" id="439" name="/root/temp2/spark/core/src/main/resources/org/apache/spark/ui/static/webui.js" package="webui.js" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="webui.js"/></testsuite><testsuite failures="0" id="440" name="/root/.m2/repository/org/apache/xbean/xbean-asm9-shaded/4.20/xbean-asm9-shaded-4.20.jar" package="xbean-asm9-shaded-4.20.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="xbean-asm9-shaded-4.20.jar"/></testsuite><testsuite failures="0" id="441" name="/root/.m2/repository/org/tukaani/xz/1.8/xz-1.8.jar" package="xz-1.8.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="xz-1.8.jar"/></testsuite><testsuite failures="1" id="442" name="/root/.m2/repository/org/apache/zookeeper/zookeeper/3.6.2/zookeeper-3.6.2.jar" package="zookeeper-3.6.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="CVE-2021-21409" name="pkg:maven/org.apache.zookeeper/zookeeper@3.6.2"><failure message="cvssV3: MEDIUM, score: 5.9 (CVSS:/AV:N/AC:H/PR:N/UI:N/S:U/C:N/I:H/A:N)"/><system-out>Netty is an open-source, asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers &amp; clients. In Netty (io.netty:netty-codec-http2) before version 4.1.61.Final there is a vulnerability that enables request smuggling. The content-length header is not correctly validated if the request only uses a single Http2HeaderFrame with the endStream set to to true. This could lead to request smuggling if the request is proxied to a remote peer and translated to HTTP/1.1. This is a followup of GHSA-wm47-8v5p-wjpj/CVE-2021-21295 which did miss to fix this one case. This was fixed as part of 4.1.61.Final.</system-out><system-err>location: /root/.m2/repository/org/apache/zookeeper/zookeeper/3.6.2/zookeeper-3.6.2.jar</system-err></testcase></testsuite><testsuite failures="0" id="443" name="/root/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.6.2/zookeeper-jute-3.6.2.jar" package="zookeeper-jute-3.6.2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="zookeeper-jute-3.6.2.jar"/></testsuite><testsuite failures="0" id="444" name="/root/.m2/repository/com/github/luben/zstd-jni/1.5.0-2/zstd-jni-1.5.0-2.jar" package="zstd-jni-1.5.0-2.jar" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="zstd-jni-1.5.0-2.jar"/></testsuite><testsuite failures="0" id="445" name="/root/.m2/repository/com/github/luben/zstd-jni/1.5.0-2/zstd-jni-1.5.0-2.jar/win/amd64/libzstd-jni-1.5.0-2.dll" package="zstd-jni-1.5.0-2.jar: libzstd-jni-1.5.0-2.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="zstd-jni-1.5.0-2.jar: libzstd-jni-1.5.0-2.dll"/></testsuite><testsuite failures="0" id="446" name="/root/.m2/repository/com/github/luben/zstd-jni/1.5.0-2/zstd-jni-1.5.0-2.jar/win/x86/libzstd-jni-1.5.0-2.dll" package="zstd-jni-1.5.0-2.jar: libzstd-jni-1.5.0-2.dll" skipped="0" tests="1" timestamp="2021-07-09T01:46:08.258"><testcase classname="dependency-check" name="zstd-jni-1.5.0-2.jar: libzstd-jni-1.5.0-2.dll"/></testsuite></testsuites>